(function (global, factory) {
  if (typeof define === "function" && define.amd) {
    define(["exports", "@babel/runtime/regenerator", "@babel/runtime/helpers/defineProperty", "@babel/runtime/helpers/objectWithoutProperties", "@babel/runtime/helpers/asyncToGenerator", "@babel/runtime/helpers/classCallCheck", "@babel/runtime/helpers/createClass", "path", "./file-utils", "./preprocessing", "./word-embeddings", "@tensorflow/tfjs-node", "./utils", "./constants", "./prediction", "./ner"], factory);
  } else if (typeof exports !== "undefined") {
    factory(exports, require("@babel/runtime/regenerator"), require("@babel/runtime/helpers/defineProperty"), require("@babel/runtime/helpers/objectWithoutProperties"), require("@babel/runtime/helpers/asyncToGenerator"), require("@babel/runtime/helpers/classCallCheck"), require("@babel/runtime/helpers/createClass"), require("path"), require("./file-utils"), require("./preprocessing"), require("./word-embeddings"), require("@tensorflow/tfjs-node"), require("./utils"), require("./constants"), require("./prediction"), require("./ner"));
  } else {
    var mod = {
      exports: {}
    };
    factory(mod.exports, global.regenerator, global.defineProperty, global.objectWithoutProperties, global.asyncToGenerator, global.classCallCheck, global.createClass, global.path, global.fileUtils, global.preprocessing, global.wordEmbeddings, global.tfjsNode, global.utils, global.constants, global.prediction, global.ner);
    global.botonicNlu = mod.exports;
  }
})(this, function (_exports, _regenerator, _defineProperty2, _objectWithoutProperties2, _asyncToGenerator2, _classCallCheck2, _createClass2, _path, _fileUtils, _preprocessing, _wordEmbeddings, tf, _utils, _constants, _prediction, _ner) {
  "use strict";

  var _interopRequireWildcard = require("@babel/runtime/helpers/interopRequireWildcard");

  var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");

  Object.defineProperty(_exports, "__esModule", {
    value: true
  });
  _exports.BotonicNLU = void 0;
  _regenerator = _interopRequireDefault(_regenerator);
  _defineProperty2 = _interopRequireDefault(_defineProperty2);
  _objectWithoutProperties2 = _interopRequireDefault(_objectWithoutProperties2);
  _asyncToGenerator2 = _interopRequireDefault(_asyncToGenerator2);
  _classCallCheck2 = _interopRequireDefault(_classCallCheck2);
  _createClass2 = _interopRequireDefault(_createClass2);
  _path = _interopRequireDefault(_path);
  tf = _interopRequireWildcard(tf);

  function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }

  function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(source, true).forEach(function (key) { (0, _defineProperty2["default"])(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(source).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

  var BotonicNLU =
  /*#__PURE__*/
  function () {
    function BotonicNLU(langs) {
      (0, _classCallCheck2["default"])(this, BotonicNLU);
      this.languages = langs;
      this.nluPath = '';
      this.utterancesPath = '';
      this.modelsPath = '';
      this.devData = {};
      this.models = {};
    }

    (0, _createClass2["default"])(BotonicNLU, [{
      key: "train",
      value: function () {
        var _train = (0, _asyncToGenerator2["default"])(
        /*#__PURE__*/
        _regenerator["default"].mark(function _callee(_ref) {
          var nluPath, _iteratorNormalCompletion, _didIteratorError, _iteratorError, _iterator, _step, config, devIntents, devEntities, params, start, _preprocessData, tensorData, tensorLabels, vocabulary, vocabularyLength, embeddingMatrix, history, end, nluData;

          return _regenerator["default"].wrap(function _callee$(_context) {
            while (1) {
              switch (_context.prev = _context.next) {
                case 0:
                  nluPath = _ref.nluPath;
                  // TODO: Think about passing an arg for using models in memory
                  this.nluPath = nluPath;
                  this.utterancesPath = _path["default"].join(nluPath, _constants.UTTERANCES_DIRNAME);
                  this.modelsPath = _path["default"].join(nluPath, _constants.MODELS_DIRNAME);

                  try {
                    this.configsByLang = (0, _fileUtils.loadConfigAndTrainingData)(this.nluPath, this.languages);
                  } catch (e) {
                    console.log(e);
                  }

                  _iteratorNormalCompletion = true;
                  _didIteratorError = false;
                  _iteratorError = undefined;
                  _context.prev = 8;
                  _iterator = this.configsByLang[Symbol.iterator]();

                case 10:
                  if (_iteratorNormalCompletion = (_step = _iterator.next()).done) {
                    _context.next = 35;
                    break;
                  }

                  config = _step.value;
                  devIntents = config.devIntents, devEntities = config.devEntities, params = (0, _objectWithoutProperties2["default"])(config, ["devIntents", "devEntities"]);
                  params = _objectSpread({}, _constants.DEFAULT_HYPERPARAMETERS, {}, params);
                  (0, _utils.printPrettyConfig)(params);
                  start = new Date();
                  _preprocessData = (0, _preprocessing.preprocessData)(devIntents, params), tensorData = _preprocessData.tensorData, tensorLabels = _preprocessData.tensorLabels, vocabulary = _preprocessData.vocabulary, vocabularyLength = _preprocessData.vocabularyLength;
                  _context.next = 19;
                  return (0, _wordEmbeddings.getEmbeddingMatrix)({
                    vocabulary: vocabulary,
                    vocabularyLength: vocabularyLength,
                    params: params
                  });

                case 19:
                  embeddingMatrix = _context.sent;
                  this.models[params.language] = embeddingLSTMModel({
                    params: params,
                    vocabularyLength: vocabularyLength,
                    embeddingMatrix: tf.tensor(embeddingMatrix),
                    outputDim: Object.keys(devIntents.intentsDict).length
                  });
                  this.models[params.language].summary();
                  this.models[params.language].compile({
                    optimizer: tf.train.adam(params.LEARNING_RATE),
                    loss: 'categoricalCrossentropy',
                    metrics: ['accuracy']
                  });
                  console.log('TRAINING...');
                  _context.next = 26;
                  return this.models[params.language].fit(tensorData, tensorLabels, {
                    epochs: params.EPOCHS,
                    validationSplit: params.VALIDATION_SPLIT
                  });

                case 26:
                  history = _context.sent;
                  end = new Date() - start;
                  console.log("\nTOTAL TRAINING TIME: ".concat(end, "ms"));
                  nluData = {
                    maxSeqLength: params.MAX_SEQ_LENGTH,
                    vocabulary: vocabulary,
                    intentsDict: devIntents.intentsDict,
                    language: params.language,
                    devEntities: devEntities
                  };
                  _context.next = 32;
                  return (0, _fileUtils.saveConfigAndTrainingData)({
                    modelsPath: this.modelsPath,
                    model: this.models[params.language],
                    language: params.language,
                    nluData: nluData
                  });

                case 32:
                  _iteratorNormalCompletion = true;
                  _context.next = 10;
                  break;

                case 35:
                  _context.next = 41;
                  break;

                case 37:
                  _context.prev = 37;
                  _context.t0 = _context["catch"](8);
                  _didIteratorError = true;
                  _iteratorError = _context.t0;

                case 41:
                  _context.prev = 41;
                  _context.prev = 42;

                  if (!_iteratorNormalCompletion && _iterator["return"] != null) {
                    _iterator["return"]();
                  }

                case 44:
                  _context.prev = 44;

                  if (!_didIteratorError) {
                    _context.next = 47;
                    break;
                  }

                  throw _iteratorError;

                case 47:
                  return _context.finish(44);

                case 48:
                  return _context.finish(41);

                case 49:
                case "end":
                  return _context.stop();
              }
            }
          }, _callee, this, [[8, 37, 41, 49], [42,, 44, 48]]);
        }));

        function train(_x) {
          return _train.apply(this, arguments);
        }

        return train;
      }()
    }, {
      key: "loadModels",
      value: function () {
        var _loadModels = (0, _asyncToGenerator2["default"])(
        /*#__PURE__*/
        _regenerator["default"].mark(function _callee2(_ref2) {
          var modelsPath, models, _iteratorNormalCompletion2, _didIteratorError2, _iteratorError2, _iterator2, _step2, language;

          return _regenerator["default"].wrap(function _callee2$(_context2) {
            while (1) {
              switch (_context2.prev = _context2.next) {
                case 0:
                  modelsPath = _ref2.modelsPath;
                  models = {};
                  models.languages = (0, _fileUtils.readDir)(modelsPath);
                  _iteratorNormalCompletion2 = true;
                  _didIteratorError2 = false;
                  _iteratorError2 = undefined;
                  _context2.prev = 6;
                  _iterator2 = models.languages[Symbol.iterator]();

                case 8:
                  if (_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done) {
                    _context2.next = 18;
                    break;
                  }

                  language = _step2.value;
                  models[language] = {};
                  models[language].nluData = (0, _fileUtils.readJSON)(_path["default"].join(modelsPath, language, _constants.NLU_DATA_FILENAME));
                  _context2.next = 14;
                  return tf.loadLayersModel("file://".concat(modelsPath, "/").concat(language, "/").concat(_constants.MODEL_FILENAME));

                case 14:
                  models[language].model = _context2.sent;

                case 15:
                  _iteratorNormalCompletion2 = true;
                  _context2.next = 8;
                  break;

                case 18:
                  _context2.next = 24;
                  break;

                case 20:
                  _context2.prev = 20;
                  _context2.t0 = _context2["catch"](6);
                  _didIteratorError2 = true;
                  _iteratorError2 = _context2.t0;

                case 24:
                  _context2.prev = 24;
                  _context2.prev = 25;

                  if (!_iteratorNormalCompletion2 && _iterator2["return"] != null) {
                    _iterator2["return"]();
                  }

                case 27:
                  _context2.prev = 27;

                  if (!_didIteratorError2) {
                    _context2.next = 30;
                    break;
                  }

                  throw _iteratorError2;

                case 30:
                  return _context2.finish(27);

                case 31:
                  return _context2.finish(24);

                case 32:
                  return _context2.abrupt("return", models);

                case 33:
                case "end":
                  return _context2.stop();
              }
            }
          }, _callee2, null, [[6, 20, 24, 32], [25,, 27, 31]]);
        }));

        function loadModels(_x2) {
          return _loadModels.apply(this, arguments);
        }

        return loadModels;
      }()
    }, {
      key: "predict",
      value: function predict(models, input) {
        var language = (0, _preprocessing.detectLang)(input, models.languages);
        var _models$language = models[language],
            model = _models$language.model,
            nluData = _models$language.nluData;
        var prediction = (0, _prediction.getPrediction)(input, model, nluData);
        var intent = (0, _prediction.getIntent)(prediction, nluData.intentsDict, language);
        var entities = (0, _ner.getEntities)(input, nluData.devEntities);
        return {
          intent: intent,
          entities: entities
        };
      } // static async interactive({ modelsPath, languages }) {
      //   let wantsInteractiveMode = await askForInteractiveMode()
      //   if (wantsInteractiveMode.affirmative) {
      //     let modelsLanguages =
      //       parseLangFlag(process.argv) || languages || readDir(modelsPath)
      //     let nlus = {}
      //     for (let lang of modelsLanguages) {
      //       nlus[`${lang}`] = {}
      //       nlus[`${lang}`].nluData = readJSON(
      //         path.join(modelsPath, lang, NLU_DATA_FILENAME)
      //       )
      //       nlus[`${lang}`].model = await tf.loadLayersModel(
      //         `file://${modelsPath}/${lang}/${MODEL_FILENAME}`
      //       )
      //     }
      //     interactiveMode(nlus)
      //   }
      // }

    }]);
    return BotonicNLU;
  }();

  _exports.BotonicNLU = BotonicNLU;

  function embeddingLSTMModel(_ref3) {
    var vocabularyLength = _ref3.vocabularyLength,
        embeddingMatrix = _ref3.embeddingMatrix,
        params = _ref3.params,
        outputDim = _ref3.outputDim;
    var model = tf.sequential();
    model.add(tf.layers.embedding({
      inputDim: vocabularyLength,
      outputDim: params.EMBEDDING_DIM,
      inputLength: params.MAX_SEQ_LENGTH,
      trainable: params.TRAINABLE_EMBEDDINGS,
      weights: [embeddingMatrix]
    }));
    model.add( // tf.layers.bidirectional({
    //   layer: tf.layers.lstm({
    //     units: params.UNITS,
    //     dropout: params.DROPOUT_REG,
    //     recurrentDropout: params.DROPOUT_REG
    //   })
    // })
    tf.layers.lstm({
      units: params.UNITS,
      dropout: params.DROPOUT_REG,
      recurrentDropout: params.DROPOUT_REG
    }));
    model.add(tf.layers.dense({
      units: outputDim,
      activation: 'softmax'
    }));
    return model;
  }
});